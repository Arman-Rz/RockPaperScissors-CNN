{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b2b271-7d0a-469e-ba18-2f16b52660fa",
   "metadata": {},
   "source": [
    "# Model B — Residual CNN (Lite, Pre-Activation) + Hyperparameter Tuning\n",
    "\n",
    "**Idea:** A compact **pre-activation ResNet**: norm → ReLU → Conv, with **projection shortcuts** on downsample blocks and light dropout.  \n",
    "**Why:** Residual connections stabilize training and let us scale depth/width modestly on a small dataset without blowing up compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ffc69-cc4e-43ba-8693-de17a1e5ab86",
   "metadata": {},
   "source": [
    "## 1) Imports, Paths & Config\n",
    "\n",
    "We load the preprocessing configuration (`preprocess.json`) to stay consistent with the data pipeline (image size, normalization, augmentation).  \n",
    "We also read the class list from CSVs to keep a fixed label ordering across train/val/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f2da6-bd66-4497-935e-85dfbf04e46b",
   "metadata": {
    "id": "670f2da6-bd66-4497-935e-85dfbf04e46b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, time, math, csv, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from keras import layers, regularizers\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e18648-e864-47c1-91f1-96bee7849a19",
   "metadata": {},
   "source": [
    "## 2) Input Pipeline\n",
    "\n",
    "- **Decode**: `tf.io.read_file` → `tf.io.decode_image` (RGB)  \n",
    "- **Geometry**: `pad_to_square` (preserves aspect), then `tf.image.resize` to `IMG_SIZE×IMG_SIZE`  \n",
    "- **Normalize**: rescale to `[0, 1]` (or standardize, per config)  \n",
    "- **Augment (train only)**: flip, slight rotation/zoom/contrast  \n",
    "- **tf.data**: `shuffle` (train), `map`, `batch`, `prefetch(AUTOTUNE)`  \n",
    "\n",
    "> This ensures identical preprocessing between all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bf228-60df-48b9-9e2c-4fdcaf1fcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\".\").resolve()\n",
    "RPS = ROOT / \"rps_outputs\"\n",
    "TRAIN_CSV = RPS / \"train.csv\"\n",
    "VAL_CSV = RPS / \"val.csv\"\n",
    "TEST_CSV = RPS / \"test.csv\"\n",
    "PREPROC_JSON = RPS / \"preprocess.json\"\n",
    "\n",
    "for p in [RPS, TRAIN_CSV, VAL_CSV]:\n",
    "    print(p, \"OK\" if p.exists() else \"MISSING\")\n",
    "\n",
    "if PREPROC_JSON.exists():\n",
    "    PREPROC = json.loads(PREPROC_JSON.read_text())\n",
    "else:\n",
    "    PREPROC = {\n",
    "    \"seed\": 42,\n",
    "    \"img_size\": 128,\n",
    "    \"resize\": { \"mode\": \"pad\", \"width\": 128, \"hright\": 128, \"pad_color\": [0, 0, 0]},\n",
    "    \"normalize\": { \"type\": \"rescale\", \"scale\": 1/255.0},\n",
    "    \"augment\": { \"flip_horizontal\": True, \"rotation\": 0.08, \"zoom\": 0.10, \"contrast\": 0.10}\n",
    "}\n",
    "\n",
    "print(\"PREPROC:\", json.dumps(PREPROC, indent=2)[:400], \"...\")\n",
    "\n",
    "IMG_SIZE = PREPROC[\"img_size\"]\n",
    "SEED = int(PREPROC.get(\"seed\", 42))\n",
    "\n",
    "def collect_classes(*csv_paths):\n",
    "    labels = set()\n",
    "    for p in csv_paths:\n",
    "        if p.exists():\n",
    "            with open(p, newline=\"\") as f:\n",
    "                rdr = csv.DictReader(f)\n",
    "                for row in rdr:\n",
    "                    labels.add(row[\"label\"])\n",
    "    classes = sorted(labels)\n",
    "    label2id = {c:i for i,c in enumerate(classes)}\n",
    "    return classes, label2id\n",
    "\n",
    "CLASSES, LABEL2ID = collect_classes(TRAIN_CSV, VAL_CSV, TEST_CSV)\n",
    "print(\"classes:\", CLASSES)\n",
    "print(\"label2id:\", LABEL2ID)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_SIZE = int(PREPROC.get(\"img_size\", 128))\n",
    "RESIZE = PREPROC.get(\"resize\", {})\n",
    "TARGET_H = int(RESIZE.get(\"height\", IMG_SIZE))\n",
    "TARGET_W = int(RESIZE.get(\"width\", IMG_SIZE))\n",
    "MODE = RESIZE.get(\"mode\", \"pad\")\n",
    "PAD_COLOR = tuple(RESIZE.get(\"pad_color\", [0, 0, 0]))\n",
    "\n",
    "NORM = PREPROC.get(\"normalize\", {\"type\": \"rescale\", \"scale\":1/255.0})\n",
    "NORM_TYPE = NORM.get(\"type\", \"rescale\")\n",
    "SCALE = float(NORM.get(\"scale\", 1/255.0))\n",
    "\n",
    "AUG = PREPROC.get(\"augment\", {})\n",
    "ROT = float(AUG.get(\"rotation\", 0.0))\n",
    "ZOOM = float(AUG.get(\"zoom\", 0.0))\n",
    "CONTR = float(AUG.get(\"contrast\", 0.0))\n",
    "FLIP = bool(AUG.get(\"flip_horizontal\", False))\n",
    "\n",
    "def decode_image(path):\n",
    "    data = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(data, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    return img\n",
    "\n",
    "def pad_to_square(img):\n",
    "    h = tf.shape(img)[0]; w = tf.shape(img)[1]\n",
    "\n",
    "    dim = tf.maximum(h, w)\n",
    "\n",
    "    pad_top = (dim - h) // 2\n",
    "    pad_bottom = dim - h - pad_top\n",
    "    pad_left = (dim - w) // 2\n",
    "    pad_right = dim - w - pad_left\n",
    "\n",
    "    padded = tf.pad(img, [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], constant_values=0)\n",
    "\n",
    "    if PAD_COLOR != (0, 0, 0):\n",
    "        color = tf.reshape(tf.constant(PAD_COLOR, img.dtype), [1, 1, 3])\n",
    "        mask = tf.pad(tf.ones_like(img[:, :, 0:1], dtype=img.dtype),\n",
    "                     [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], constant_values=0)\n",
    "        bg = tf.ones_like(padded) * color\n",
    "        padded = padded*mask + bg*(1.0 - mask)\n",
    "    return padded\n",
    "\n",
    "def resize_step(img):\n",
    "    if MODE == \"pad\":\n",
    "        img = pad_to_square(img)\n",
    "    img = tf.image.resize(img, [TARGET_H, TARGET_W])\n",
    "    return img\n",
    "\n",
    "def normalize_step(img):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    if NORM_TYPE == \"rescale\":\n",
    "        img = img * SCALE\n",
    "    elif NORM_TYPE == \"standardize\":\n",
    "        img = tf.image.per_image_standardization(img)\n",
    "    else:\n",
    "        img = img * SCALE\n",
    "    return img\n",
    "\n",
    "def augment_step(img):\n",
    "    if FLIP:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "    if ZOOM > 0.0:\n",
    "        scale = 1.0 + tf.random.uniform([], -ZOOM, ZOOM)\n",
    "        h = tf.shape(img)[0]; w = tf.shape(img)[1]\n",
    "        nh = tf.cast(tf.cast(h, tf.float32) * scale, tf.int32)\n",
    "        nw = tf.cast(tf.cast(w, tf.float32) * scale, tf.int32)\n",
    "        img = tf.image.resize(img, [nh, nw])\n",
    "        img = tf.image.resize_with_crop_or_pad(img, h, w)\n",
    "    if CONTR > 0.0:\n",
    "        img = tf.image.random_contrast(img, lower=1.0-CONTR, upper=1.0+CONTR)\n",
    "    return img\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "CLASSES_T = tf.constant(CLASSES)\n",
    "IDS_T = tf.constant(list(range(NUM_CLASSES)), dtype=tf.int32)\n",
    "LABEL_TABLE = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(keys=CLASSES_T, values=IDS_T), default_value=-1\n",
    ")\n",
    "\n",
    "def parse_row(path_str, label_str, training: bool):\n",
    "    img = decode_image(path_str)\n",
    "    img = resize_step(img)\n",
    "    if training:\n",
    "        img = augment_step(img)\n",
    "    img = normalize_step(img)\n",
    "    y = tf.one_hot(LABEL_TABLE.lookup(label_str), depth=NUM_CLASSES, dtype=tf.float32)\n",
    "    return img, y\n",
    "\n",
    "def read_csv_dataset(csv_path, training: bool, batch_size=32, shuffle_buffer=2048):\n",
    "    ds = tf.data.TextLineDataset(str(csv_path)).skip(1)\n",
    "\n",
    "    def _split(line):\n",
    "        parts = tf.strings.split(line, sep=\",\")\n",
    "        return parts[0], parts[1]\n",
    "\n",
    "    ds = ds.map(_split, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(shuffle_buffer, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p,l: parse_row(p, l, training), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_ds = read_csv_dataset(TRAIN_CSV, training=True, batch_size=BATCH_SIZE)\n",
    "val_ds = read_csv_dataset(VAL_CSV, training=False, batch_size=BATCH_SIZE)\n",
    "test_ds = read_csv_dataset(TEST_CSV, training=False, batch_size=BATCH_SIZE) if TEST_CSV.exists() else None\n",
    "\n",
    "# Steps per epoch (full epochs)\n",
    "def count_rows(csv_path):\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        return sum(1 for _ in csv.DictReader(f))\n",
    "\n",
    "steps_per_epoch = math.ceil(count_rows(TRAIN_CSV) / BATCH_SIZE)\n",
    "val_steps = math.ceil(count_rows(VAL_CSV) / BATCH_SIZE)\n",
    "\n",
    "# (Optional) class weights, but cap to avoid instability\n",
    "def class_counts(csv_path):\n",
    "    cnt = Counter()\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            cnt[row[\"label\"]] += 1\n",
    "    return cnt\n",
    "\n",
    "cnts = class_counts(TRAIN_CSV)\n",
    "total = sum(cnts.values())\n",
    "raw_w = {LABEL2ID[c]: total / (NUM_CLASSES * max(1, cnts.get(c, 0))) for c in CLASSES}\n",
    "class_weights = {k: min(v, 2.0) for k, v in raw_w.items()}\n",
    "print(\"Class counts:\", cnts)\n",
    "print(\"Class weights (capped):\", class_weights)\n",
    "\n",
    "try:\n",
    "  from keras import mixed_percision\n",
    "  mixed_percision.set_global_policy(\"mixed_float16\")\n",
    "  FINAL_DTYPE = \"float32\"\n",
    "except Exception:\n",
    "  FINAL_DTYPE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08f199-b307-49e4-bdf8-2a3cf015f94e",
   "metadata": {
    "id": "5e08f199-b307-49e4-bdf8-2a3cf015f94e"
   },
   "source": [
    "## 3) Residual Block (Lite, Pre-Activation)\n",
    "- **Pre-activation**: `Norm → ReLU → Conv` (improves gradient flow vs post-activation)\n",
    "- **Projection shortcut** when downsampling or channel mismatch (1×1 conv, stride 2)\n",
    "- **Lite**: keep params small; optional second conv only on downsample blocks for stability\n",
    "- **Norm choice**: `LayerNorm` by default for small batches; switch to `BatchNorm` if batch ≥ 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef2c56-8ecd-4e08-bd35-c205be8055b6",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Space\n",
    "We tune a **small, high-impact** set:\n",
    "- `weight_decay` (L2): regularization strength  \n",
    "- `base_block_drop`: base dropout per stage (grows with depth)  \n",
    "- `dense_units`, `drop_dense`: head capacity & regularization  \n",
    "- `label_smoothing`: calibration vs overconfidence  \n",
    "- `learning_rate`: (1e-3, 7e-4, 5e-4) — stable range for Adam here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57189322-8934-4433-9f5d-fcc31a26c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(x, filters, wd):\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\",\n",
    "                     kernel_regularizer=regularizers.l2(wd))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "def residual_block_lite(x, filters, downsample=False, wd=1e-4, drop=0.0, use_ln=True):\n",
    "    Norm = (lambda: layers.LayerNormalization(epsilon=1e-5)) if use_ln else (lambda: layers.BatchNormalization())\n",
    "    shortcut = x\n",
    "    stride = 2 if downsample else 1\n",
    "\n",
    "    # Pre-Activation\n",
    "    y = Norm()(x)\n",
    "    y = layers.ReLU()(y)\n",
    "\n",
    "    # Projection if needed\n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding=\"same\", use_bias=False,\n",
    "                                kernel_regularizer=regularizers.l2(wd))(y)\n",
    "\n",
    "    # Conv 1\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\", use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(wd))(x)\n",
    "\n",
    "    # Second conv only on downsample bloscks (stability with tiny cost)\n",
    "    if downsample:\n",
    "        y = Norm()(y)\n",
    "        y = layers.ReLU()(y)\n",
    "        y = layers.Conv2D(filters, 3, strides=stride, padding=\"same\", use_bias=False,\n",
    "                                kernel_regularizer=regularizers.l2(wd))(y)\n",
    "\n",
    "    out = layers.Add()([y, shortcut])\n",
    "    out = layers.ReLU()(out)\n",
    "    if drop > 0:\n",
    "        x = layers.Dropout(drop)(out)\n",
    "    return out\n",
    "\n",
    "def build_model_b(hp, input_shape, num_classes):\n",
    "    # Search Space\n",
    "    wd           = hp.Float(\"weight_decay\", 1e-5, 3e-4, sampling=\"log\")\n",
    "    base         = hp.Choice(\"base_block_drop\", [0.05, 0.10, 0.15])\n",
    "    head_units  = hp.Choice(\"dense_units\", [96, 128, 160])\n",
    "    head_drop   = hp.Choice(\"drop_dense\", [0.2, 0.3, 0.4])\n",
    "    label_smooth = hp.Choice(\"label_smoothing\", [0.05, 0.10])\n",
    "    lr           = hp.Choice(\"learning_rate\", [1e-3, 7e-4, 5e-4])\n",
    "    use_ln = True    # Set False if batch > 64\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(wd))(inputs)\n",
    "\n",
    "    d0, d1, d2 = base, base+0.05, base+0.10\n",
    "    # Stage 1\n",
    "    x = residual_block_lite(x, 32, downsample=False, wd=wd, drop=d0, use_ln=use_ln)\n",
    "\n",
    "    # Stage 2\n",
    "    x = residual_block_lite(x, 64, downsample=True, wd=wd, drop=d1, use_ln=use_ln)\n",
    "    x = residual_block_lite(x, 64, downsample=False, wd=wd, drop=d1, use_ln=use_ln)\n",
    "\n",
    "    # Stage 3\n",
    "    x = residual_block_lite(x, 128, downsample=True, wd=wd, drop=d2, use_ln=use_ln)\n",
    "    x = residual_block_lite(x, 128, downsample=False, wd=wd, drop=d2, use_ln=use_ln)\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-4)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(head_units, activation=\"relu\",\n",
    "                    kernel_regularizer=regularizers.l2(wd))(x)\n",
    "    x = layers.Dropout(head_drop)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=\"ModelB_Residual\")\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = keras.losses.CategoricalCrossentropy(label_smoothing=label_smooth)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bszH-pAT5xC3",
   "metadata": {
    "id": "bszH-pAT5xC3"
   },
   "source": [
    "## 4) KerasTuner — Bayesian Optimization\n",
    "- Objective: **maximize `val_accuracy`**  \n",
    "- 12 trials, early stopping on val metrics  \n",
    "- We train with `.repeat()` + fixed `steps_per_epoch/validation_steps` for **complete epochs**, stable callbacks, and fair comparison across trials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QoUdztHM5s9Z",
   "metadata": {
    "id": "QoUdztHM5s9Z"
   },
   "outputs": [],
   "source": [
    "tuner_b = kt.BayesianOptimization(\n",
    "    hypermodel=lambda hp: build_model_b(hp, input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES),\n",
    "    objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=12,                 \n",
    "    executions_per_trial=1,\n",
    "    directory=Path(\"rps_outputs/hpo\"),\n",
    "    project_name=\"model_b_residual\",\n",
    "    overwrite=True,\n",
    "    max_consecutive_failed_trials=20,\n",
    ")\n",
    "\n",
    "search_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "SEARCH_STEPS = steps_per_epoch      \n",
    "SEARCH_VAL_STEPS = val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uCuPuP7r7vxv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3071785,
     "status": "ok",
     "timestamp": 1760554575639,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "uCuPuP7r7vxv",
    "outputId": "d6c78224-c75e-4986-bf0f-ce4f478187e8"
   },
   "outputs": [],
   "source": [
    "tuner_b.search(\n",
    "    train_ds.repeat(),\n",
    "    validation_data=val_ds.repeat(),\n",
    "    steps_per_epoch=SEARCH_STEPS,\n",
    "    validation_steps=SEARCH_VAL_STEPS,\n",
    "    epochs=36,\n",
    "    callbacks=search_callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "best_hps_b = tuner_b.get_best_hyperparameters(1)[0]\n",
    "print(\"Best HPs (Model B):\", best_hps_b.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LgPq_5ZCN6qd",
   "metadata": {
    "id": "LgPq_5ZCN6qd"
   },
   "source": [
    "## 5) Final Training (Best HPs)\n",
    "- Reload best hyperparameters → rebuild model  \n",
    "- Use a **slightly longer** schedule with patience on `val_loss` and LR reduction on plateau  \n",
    "- Keep class weights **off** for this balanced dataset (they’re computed but not needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IItCR5MPOFBo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1760555103196,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "IItCR5MPOFBo",
    "outputId": "5559594d-c394-472d-d432-b183bdbf7718"
   },
   "outputs": [],
   "source": [
    "MODEL_B = tuner_b.hypermodel.build(best_hps_b)\n",
    "\n",
    "full_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(str(RPS / \"checkpoints/model_b_best.keras\"),\n",
    "                                    monitor=\"val_accuracy\", mode=\"max\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "history_b = MODEL_B.fit(\n",
    "    train_ds.repeat(),\n",
    "    validation_data=val_ds.repeat(),\n",
    "    steps_per_epoch=SEARCH_STEPS,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=40,\n",
    "    callbacks=full_callbacks,\n",
    "    class_weight=class_weights,\n",
    ")\n",
    "\n",
    "print(dict(zip(MODEL_B.metrics_names, MODEL_B.evaluate(test_ds, verbose=0))))\n",
    "MODEL_B.save(\"rps_outputs/model_b_hpo_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90577880-9e0e-43f1-a47f-631baefca7da",
   "metadata": {},
   "source": [
    "## 5) Evaluation & Diagnostics\n",
    "\n",
    "- Run predictions on **test** (or val if test is absent)\n",
    "- Report **confusion matrix** and **classification report** (precision/recall/F1 by class)\n",
    "- Save final **test metrics** to JSON for the report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d3986-5981-4ac1-9948-0ee1c3c8d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "for x,y in (test_ds or val_ds):\n",
    "    p = MODEL_B.predict(x, verbose=0)\n",
    "    y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(p, axis=1))\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c43860-63c9-411f-8ffa-50d9a73e14d3",
   "metadata": {},
   "source": [
    "## 6) Learning Curves\n",
    "\n",
    "We plot accuracy and loss for train vs. validation to:\n",
    "- Spot **overfitting** (train ↑, val ↔/↓)\n",
    "- Verify **convergence** (both curves stabilize)\n",
    "- Compare across experiments quickly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xmpXliJPjcM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 2175,
     "status": "ok",
     "timestamp": 1760555113497,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "0xmpXliJPjcM",
    "outputId": "323d64af-635e-4d7f-8468-52cdb285b8c0"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_b.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history_b.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(\"Model B Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_b.history[\"loss\"], label=\"train_acc\")\n",
    "plt.plot(history_b.history[\"val_loss\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"Model B Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab53594-dba4-41ad-ac19-143296e243dc",
   "metadata": {
    "id": "1ab53594-dba4-41ad-ac19-143296e243dc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
