{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c638c80-e874-4fee-b4e8-07adc7717297",
   "metadata": {},
   "source": [
    "# Model A — Baseline CNN (Instructional)\n",
    "\n",
    "**Goal:** Train a simple baseline CNN on Rock–Paper–Scissors to establish a reference point.  \n",
    "**Pipeline summary:** We reuse the `tf.data` input pipeline defined earlier (CSV → decode → pad/resize → normalize → augment(train)).  \n",
    "**Why baseline?** A compact model helps verify the pipeline, detect bugs (e.g., label mismatches), and set a minimum bar for accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b780e9-7a9a-4334-b202-2a926d15a33d",
   "metadata": {},
   "source": [
    "## 1) Imports, Paths & Config\n",
    "\n",
    "We load the preprocessing configuration (`preprocess.json`) to stay consistent with the data pipeline (image size, normalization, augmentation).  \n",
    "We also read the class list from CSVs to keep a fixed label ordering across train/val/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c2374-26ec-4804-aacf-76ef5d668836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, csv, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, regularizers\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a33ff-d910-4662-8a62-7530a0f25834",
   "metadata": {},
   "source": [
    "## 2) Input Pipeline\n",
    "\n",
    "- **Decode**: `tf.io.read_file` → `tf.io.decode_image` (RGB)  \n",
    "- **Geometry**: `pad_to_square` (preserves aspect), then `tf.image.resize` to `IMG_SIZE×IMG_SIZE`  \n",
    "- **Normalize**: rescale to `[0, 1]` (or standardize, per config)  \n",
    "- **Augment (train only)**: flip, slight rotation/zoom/contrast  \n",
    "- **tf.data**: `shuffle` (train), `map`, `batch`, `prefetch(AUTOTUNE)`  \n",
    "\n",
    "> This ensures identical preprocessing between all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893ca53-6277-43cd-b2c3-9a18ec818fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\".\").resolve()\n",
    "RPS = ROOT / \"rps_outputs\"\n",
    "TRAIN_CSV = RPS / \"train.csv\"\n",
    "VAL_CSV = RPS / \"val.csv\"\n",
    "TEST_CSV = RPS / \"test.csv\"\n",
    "PREPROC_JSON = RPS / \"preprocess.json\"\n",
    "\n",
    "for p in [RPS, TRAIN_CSV, VAL_CSV]:\n",
    "    print(p, \"OK\" if p.exists() else \"MISSING\")\n",
    "\n",
    "if PREPROC_JSON.exists():\n",
    "    PREPROC = json.loads(PREPROC_JSON.read_text())\n",
    "else:\n",
    "    PREPROC = {\n",
    "    \"seed\": 42,\n",
    "    \"img_size\": 128,\n",
    "    \"resize\": { \"mode\": \"pad\", \"width\": 128, \"hright\": 128, \"pad_color\": [0, 0, 0]},\n",
    "    \"normalize\": { \"type\": \"rescale\", \"scale\": 1/255.0},\n",
    "    \"augment\": { \"flip_horizontal\": True, \"rotation\": 0.08, \"zoom\": 0.10, \"contrast\": 0.10}\n",
    "}\n",
    "\n",
    "print(\"PREPROC:\", json.dumps(PREPROC, indent=2)[:400], \"...\")\n",
    "\n",
    "IMG_SIZE = PREPROC[\"img_size\"]\n",
    "SEED = int(PREPROC.get(\"seed\", 42))\n",
    "\n",
    "def collect_classes(*csv_paths):\n",
    "    labels = set()\n",
    "    for p in csv_paths:\n",
    "        if p.exists():\n",
    "            with open(p, newline=\"\") as f:\n",
    "                rdr = csv.DictReader(f)\n",
    "                for row in rdr:\n",
    "                    labels.add(row[\"label\"])\n",
    "    classes = sorted(labels)\n",
    "    label2id = {c:i for i,c in enumerate(classes)}\n",
    "    return classes, label2id\n",
    "\n",
    "CLASSES, LABEL2ID = collect_classes(TRAIN_CSV, VAL_CSV, TEST_CSV)\n",
    "print(\"classes:\", CLASSES)\n",
    "print(\"label2id:\", LABEL2ID)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_SIZE = int(PREPROC.get(\"img_size\", 128))\n",
    "RESIZE = PREPROC.get(\"resize\", {})\n",
    "TARGET_H = int(RESIZE.get(\"height\", IMG_SIZE))\n",
    "TARGET_W = int(RESIZE.get(\"width\", IMG_SIZE))\n",
    "MODE = RESIZE.get(\"mode\", \"pad\")\n",
    "PAD_COLOR = tuple(RESIZE.get(\"pad_color\", [0, 0, 0]))\n",
    "\n",
    "NORM = PREPROC.get(\"normalize\", {\"type\": \"rescale\", \"scale\":1/255.0})\n",
    "NORM_TYPE = NORM.get(\"type\", \"rescale\")\n",
    "SCALE = float(NORM.get(\"scale\", 1/255.0))\n",
    "\n",
    "AUG = PREPROC.get(\"augment\", {})\n",
    "ROT = float(AUG.get(\"rotation\", 0.0))\n",
    "ZOOM = float(AUG.get(\"zoom\", 0.0))\n",
    "CONTR = float(AUG.get(\"contrast\", 0.0))\n",
    "FLIP = bool(AUG.get(\"flip_horizontal\", False))\n",
    "\n",
    "def decode_image(path):\n",
    "    data = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(data, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    return img\n",
    "\n",
    "def pad_to_square(img):\n",
    "    h = tf.shape(img)[0]; w = tf.shape(img)[1]\n",
    "\n",
    "    dim = tf.maximum(h, w)\n",
    "\n",
    "    pad_top = (dim - h) // 2\n",
    "    pad_bottom = dim - h - pad_top\n",
    "    pad_left = (dim - w) // 2\n",
    "    pad_right = dim - w - pad_left\n",
    "\n",
    "    padded = tf.pad(img, [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], constant_values=0)\n",
    "\n",
    "    if PAD_COLOR != (0, 0, 0):\n",
    "        color = tf.reshape(tf.constant(PAD_COLOR, img.dtype), [1, 1, 3])\n",
    "        mask = tf.pad(tf.ones_like(img[:, :, 0:1], dtype=img.dtype),\n",
    "                     [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], constant_values=0)\n",
    "        bg = tf.ones_like(padded) * color\n",
    "        padded = padded*mask + bg*(1.0 - mask)\n",
    "    return padded\n",
    "\n",
    "def resize_step(img):\n",
    "    if MODE == \"pad\":\n",
    "        img = pad_to_square(img)\n",
    "    img = tf.image.resize(img, [TARGET_H, TARGET_W])\n",
    "    return img\n",
    "\n",
    "def normalize_step(img):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    if NORM_TYPE == \"rescale\":\n",
    "        img = img * SCALE\n",
    "    elif NORM_TYPE == \"standardize\":\n",
    "        img = tf.image.per_image_standardization(img)\n",
    "    else:\n",
    "        img = img * SCALE\n",
    "    return img\n",
    "\n",
    "def augment_step(img):\n",
    "    if FLIP:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "    if ZOOM > 0.0:\n",
    "        scale = 1.0 + tf.random.uniform([], -ZOOM, ZOOM)\n",
    "        h = tf.shape(img)[0]; w = tf.shape(img)[1]\n",
    "        nh = tf.cast(tf.cast(h, tf.float32) * scale, tf.int32)\n",
    "        nw = tf.cast(tf.cast(w, tf.float32) * scale, tf.int32)\n",
    "        img = tf.image.resize(img, [nh, nw])\n",
    "        img = tf.image.resize_with_crop_or_pad(img, h, w)\n",
    "    if CONTR > 0.0:\n",
    "        img = tf.image.random_contrast(img, lower=1.0-CONTR, upper=1.0+CONTR)\n",
    "    return img\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "CLASSES_T = tf.constant(CLASSES)\n",
    "IDS_T = tf.constant(list(range(NUM_CLASSES)), dtype=tf.int32)\n",
    "LABEL_TABLE = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(keys=CLASSES_T, values=IDS_T), default_value=-1\n",
    ")\n",
    "\n",
    "def parse_row(path_str, label_str, training: bool):\n",
    "    img = decode_image(path_str)\n",
    "    img = resize_step(img)\n",
    "    if training:\n",
    "        img = augment_step(img)\n",
    "    img = normalize_step(img)\n",
    "    y = tf.one_hot(LABEL_TABLE.lookup(label_str), depth=NUM_CLASSES, dtype=tf.float32)\n",
    "    return img, y\n",
    "\n",
    "def read_csv_dataset(csv_path, training: bool, batch_size=32, shuffle_buffer=2048):\n",
    "    ds = tf.data.TextLineDataset(str(csv_path)).skip(1)\n",
    "\n",
    "    def _split(line):\n",
    "        parts = tf.strings.split(line, sep=\",\")\n",
    "        return parts[0], parts[1]\n",
    "\n",
    "    ds = ds.map(_split, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(shuffle_buffer, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p,l: parse_row(p, l, training), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_ds = read_csv_dataset(TRAIN_CSV, training=True, batch_size=BATCH_SIZE)\n",
    "val_ds = read_csv_dataset(VAL_CSV, training=False, batch_size=BATCH_SIZE)\n",
    "test_ds = read_csv_dataset(TEST_CSV, training=False, batch_size=BATCH_SIZE) if TEST_CSV.exists() else None\n",
    "\n",
    "# Steps per epoch (full epochs)\n",
    "def count_rows(csv_path):\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        return sum(1 for _ in csv.DictReader(f))\n",
    "\n",
    "steps_per_epoch = math.ceil(count_rows(TRAIN_CSV) / BATCH_SIZE)\n",
    "val_steps = math.ceil(count_rows(VAL_CSV) / BATCH_SIZE)\n",
    "\n",
    "# (Optional) class weights, but cap to avoid instability\n",
    "def class_counts(csv_path):\n",
    "    cnt = Counter()\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            cnt[row[\"label\"]] += 1\n",
    "    return cnt\n",
    "\n",
    "cnts = class_counts(TRAIN_CSV)\n",
    "total = sum(cnts.values())\n",
    "raw_w = {LABEL2ID[c]: total / (NUM_CLASSES * max(1, cnts.get(c, 0))) for c in CLASSES}\n",
    "class_weights = {k: min(v, 2.0) for k, v in raw_w.items()}\n",
    "print(\"Class counts:\", cnts)\n",
    "print(\"Class weights (capped):\", class_weights)\n",
    "\n",
    "try:\n",
    "  from keras import mixed_percision\n",
    "  mixed_percision.set_global_policy(\"mixed_float16\")\n",
    "  FINAL_DTYPE = \"float32\"\n",
    "except Exception:\n",
    "  FINAL_DTYPE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe750e-ffd6-41ea-bd82-1cc1a81c86ab",
   "metadata": {},
   "source": [
    "## 3) Model A Architecture (Why this design?)\n",
    "\n",
    "- **3 conv stages** (32→64→128) with **BatchNorm** + **ReLU**  \n",
    "- **MaxPool** after first two stages (downsample); **GAP** before the head (parameter-efficient)  \n",
    "- **Dropout** grows with depth (0.10 → 0.15 → 0.30 at the dense head)  \n",
    "- **Softmax** outputs `num_classes` probabilities\n",
    "\n",
    "This is intentionally lightweight to give a quick, stable baseline on small, clean datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8be89-c3c3-496f-ae0d-ecdf15fbaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_a(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.10)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.15)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.30)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs, name=\"ModelA_Baseline\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2bc3b-be7c-45bd-bea7-f499d9625be0",
   "metadata": {},
   "source": [
    "## 4) Compile & Training Setup\n",
    "\n",
    "- **Loss**: Categorical Crossentropy  \n",
    "- **Optimizer**: Adam (default lr works well for this baseline)  \n",
    "- **Metrics**: Accuracy  \n",
    "- **Callbacks**: \n",
    "  - `ModelCheckpoint(save_best_only=True, monitor=\"val_accuracy\")`\n",
    "  - `EarlyStopping(patience=5, restore_best_weights=True)`\n",
    "\n",
    "We use `.repeat()` on datasets + fixed `steps_per_epoch`/`validation_steps` to enforce **full epochs**.  \n",
    "> Tip: Use `steps_per_epoch = ceil(train_rows / batch_size)` to cover all batches exactly once per epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72682f-f39a-4ded-989c-35c337e88f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_A = build_model_a((IMG_SIZE, IMG_SIZE, 3), NUM_CLASSES)\n",
    "\n",
    "MODEL_A.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(RPS / \"checkpoints/model_a_best.keras\"),\n",
    "        monitor=\"val_accuracy\", mode=\"max\", save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc854c4-3053-44fe-a69e-3e0889c12fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "history = MODEL_A.fit(\n",
    "    train_ds.repeat(), \n",
    "    validation_data=val_ds.repeat(), \n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=40,\n",
    "    validation_steps=20,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ee706-82a9-481b-aefc-53e484c6dca5",
   "metadata": {},
   "source": [
    "## 5) Evaluation & Diagnostics\n",
    "\n",
    "- Run predictions on **test** (or val if test is absent)\n",
    "- Report **confusion matrix** and **classification report** (precision/recall/F1 by class)\n",
    "- Save final **test metrics** to JSON for the report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656d73a-9226-4f5b-843c-f2abae94f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "for x,y in (test_ds or val_ds):\n",
    "    p = MODEL_A.predict(x, verbose=0)\n",
    "   z y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(p, axis=1))\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8b369-ac02-4783-a7a1-cc8b2c57c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_ds is not None:\n",
    "    test_metrics = MODEL_A.evaluate(test_ds, return_dict=True)\n",
    "    print(\"Test metrics:\", test_metrics)\n",
    "    with open(\"rps_outputs/model_a_test_metrics_json\", \"w\") as f:\n",
    "        json.dump({k: float(v) for k, v in test_metrics.items()}, f, indent=2)\n",
    "\n",
    "model.save(\"rps_outputs/model_a_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9cdf1-6f46-414c-986c-1b3e7599ca50",
   "metadata": {},
   "source": [
    "## 6) Learning Curves\n",
    "\n",
    "We plot accuracy and loss for train vs. validation to:\n",
    "- Spot **overfitting** (train ↑, val ↔/↓)\n",
    "- Verify **convergence** (both curves stabilize)\n",
    "- Compare across experiments quickly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f504272-bbda-4912-8fb6-565d822a804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(\"Model A Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"Model A Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
