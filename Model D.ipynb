{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195b5e44-ba4f-4927-a133-d4b6b329c43d",
   "metadata": {},
   "source": [
    "# Model D — SqueezeFire CNN with Residual Connections (Hyperparameter Tuned)\n",
    "\n",
    "**Concept:**  \n",
    "Model D is inspired by the **SqueezeNet / Fire module** family.  \n",
    "It combines **parameter-efficient channel squeezing (1×1 conv)** and **expanding (1×1 + 3×3)** layers, with **residual shortcuts** for better gradient flow.  \n",
    "\n",
    "**Goal:**  \n",
    "Achieve high accuracy at lower computational cost, test the effect of *compound scaling* (filters ×2) and *label smoothing* on generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba6f32-e76e-43be-ad44-3b1466f50e27",
   "metadata": {},
   "source": [
    "## 1) Imports, Paths & Config\n",
    "\n",
    "We load the preprocessing configuration (`preprocess.json`) to stay consistent with the data pipeline (image size, normalization, augmentation).  \n",
    "We also read the class list from CSVs to keep a fixed label ordering across train/val/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9aa01-ef19-4dfa-9c42-83d50ebc50e4",
   "metadata": {
    "executionInfo": {
     "elapsed": 2149,
     "status": "ok",
     "timestamp": 1760718787119,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "3ca9aa01-ef19-4dfa-9c42-83d50ebc50e4"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, time, math, csv, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from keras import layers, regularizers\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79761aad-416c-470e-a95e-23dcd95363ed",
   "metadata": {},
   "source": [
    "## 2) Input Pipeline\n",
    "\n",
    "- **Decode**: `tf.io.read_file` → `tf.io.decode_image` (RGB)  \n",
    "- **Geometry**: `pad_to_square` (preserves aspect), then `tf.image.resize` to `IMG_SIZE×IMG_SIZE`  \n",
    "- **Normalize**: rescale to `[0, 1]` (or standardize, per config)  \n",
    "- **Augment (train only)**: flip, slight rotation/zoom/contrast  \n",
    "- **tf.data**: `shuffle` (train), `map`, `batch`, `prefetch(AUTOTUNE)`  \n",
    "\n",
    "> This ensures identical preprocessing between all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2oBvAZxDS2hG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23405,
     "status": "ok",
     "timestamp": 1760718811516,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "2oBvAZxDS2hG",
    "outputId": "6feccaf3-cc9e-417d-ded8-4fa4a61ecf48",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ROOT = Path(\".\").resolve()\n",
    "RPS = ROOT / \"rps_outputs\"\n",
    "TRAIN_CSV = RPS / \"train.csv\"\n",
    "VAL_CSV = RPS / \"val.csv\"\n",
    "TEST_CSV = RPS / \"test.csv\"\n",
    "PREPROC_JSON = RPS / \"preprocess.json\"\n",
    "\n",
    "for p in [RPS, TRAIN_CSV, VAL_CSV]:\n",
    "    print(p, \"OK\" if p.exists() else \"MISSING\")\n",
    "\n",
    "if PREPROC_JSON.exists():\n",
    "    PREPROC = json.loads(PREPROC_JSON.read_text())\n",
    "else:\n",
    "    PREPROC = {\n",
    "    \"seed\": 42,\n",
    "    \"img_size\": 128,\n",
    "    \"resize\": { \"mode\": \"pad\", \"width\": 128, \"hright\": 128, \"pad_color\": [0, 0, 0]},\n",
    "    \"normalize\": { \"type\": \"rescale\", \"scale\": 1/255.0},\n",
    "    \"augment\": { \"flip_horizontal\": True, \"rotation\": 0.08, \"zoom\": 0.10, \"contrast\": 0.10}\n",
    "}\n",
    "\n",
    "print(\"PREPROC:\", json.dumps(PREPROC, indent=2)[:400], \"...\")\n",
    "\n",
    "IMG_SIZE = PREPROC[\"img_size\"]\n",
    "SEED = int(PREPROC.get(\"seed\", 42))\n",
    "\n",
    "def collect_classes(*csv_paths):\n",
    "    labels = set()\n",
    "    for p in csv_paths:\n",
    "        if p.exists():\n",
    "            with open(p, newline=\"\") as f:\n",
    "                rdr = csv.DictReader(f)\n",
    "                for row in rdr:\n",
    "                    labels.add(row[\"label\"])\n",
    "    classes = sorted(labels)\n",
    "    label2id = {c:i for i,c in enumerate(classes)}\n",
    "    return classes, label2id\n",
    "\n",
    "CLASSES, LABEL2ID = collect_classes(TRAIN_CSV, VAL_CSV, TEST_CSV)\n",
    "print(\"classes:\", CLASSES)\n",
    "print(\"label2id:\", LABEL2ID)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_SIZE = int(PREPROC.get(\"img_size\", 128))\n",
    "RESIZE = PREPROC.get(\"resize\", {})\n",
    "TARGET_H = int(RESIZE.get(\"height\", IMG_SIZE))\n",
    "TARGET_W = int(RESIZE.get(\"width\", IMG_SIZE))\n",
    "MODE = RESIZE.get(\"mode\", \"pad\")\n",
    "PAD_COLOR = tuple(RESIZE.get(\"pad_color\", [0, 0, 0]))\n",
    "\n",
    "NORM = PREPROC.get(\"normalize\", {\"type\": \"rescale\", \"scale\":1/255.0})\n",
    "NORM_TYPE = NORM.get(\"type\", \"rescale\")\n",
    "SCALE = float(NORM.get(\"scale\", 1/255.0))\n",
    "\n",
    "AUG = PREPROC.get(\"augment\", {})\n",
    "ROT = float(AUG.get(\"rotation\", 0.0))\n",
    "ZOOM = float(AUG.get(\"zoom\", 0.0))\n",
    "CONTR = float(AUG.get(\"contrast\", 0.0))\n",
    "FLIP = bool(AUG.get(\"flip_horizontal\", False))\n",
    "\n",
    "def decode_image(path):\n",
    "    data = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(data, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    return img\n",
    "\n",
    "def pad_to_square(img):\n",
    "    h = tf.shape(img)[0]; w = tf.shape(img)[1]\n",
    "\n",
    "    dim = tf.maximum(h, w)\n",
    "\n",
    "    pad_top = (dim - h) // 2\n",
    "    pad_bottom = dim - h - pad_top\n",
    "    pad_left = (dim - w) // 2\n",
    "    pad_right = dim - w - pad_left\n",
    "\n",
    "    padded = tf.pad(img, [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], constant_values=0)\n",
    "\n",
    "    if PAD_COLOR != (0, 0, 0):\n",
    "        color = tf.reshape(tf.constant(PAD_COLOR, img.dtype), [1, 1, 3])\n",
    "        mask = tf.pad(tf.ones_like(img[:, :, 0:1], dtype=img.dtype),\n",
    "                     [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], constant_values=0)\n",
    "        bg = tf.ones_like(padded) * color\n",
    "        padded = padded*mask + bg*(1.0 - mask)\n",
    "    return padded\n",
    "\n",
    "def resize_step(img):\n",
    "    if MODE == \"pad\":\n",
    "        img = pad_to_square(img)\n",
    "    img = tf.image.resize(img, [TARGET_H, TARGET_W])\n",
    "    return img\n",
    "\n",
    "def normalize_step(img):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    if NORM_TYPE == \"rescale\":\n",
    "        img = img * SCALE\n",
    "    elif NORM_TYPE == \"standardize\":\n",
    "        img = tf.image.per_image_standardization(img)\n",
    "    else:\n",
    "        img = img * SCALE\n",
    "    return img\n",
    "\n",
    "def augment_step(img):\n",
    "    if FLIP:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "    if ZOOM > 0.0:\n",
    "        scale = 1.0 + tf.random.uniform([], -ZOOM, ZOOM)\n",
    "        h = tf.shape(img)[0]; w = tf.shape(img)[1]\n",
    "        nh = tf.cast(tf.cast(h, tf.float32) * scale, tf.int32)\n",
    "        nw = tf.cast(tf.cast(w, tf.float32) * scale, tf.int32)\n",
    "        img = tf.image.resize(img, [nh, nw])\n",
    "        img = tf.image.resize_with_crop_or_pad(img, h, w)\n",
    "    if CONTR > 0.0:\n",
    "        img = tf.image.random_contrast(img, lower=1.0-CONTR, upper=1.0+CONTR)\n",
    "    return img\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "CLASSES_T = tf.constant(CLASSES)\n",
    "IDS_T = tf.constant(list(range(NUM_CLASSES)), dtype=tf.int32)\n",
    "LABEL_TABLE = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(keys=CLASSES_T, values=IDS_T), default_value=-1\n",
    ")\n",
    "\n",
    "def parse_row(path_str, label_str, training: bool):\n",
    "    img = decode_image(path_str)\n",
    "    img = resize_step(img)\n",
    "    if training:\n",
    "        img = augment_step(img)\n",
    "    img = normalize_step(img)\n",
    "    y = tf.one_hot(LABEL_TABLE.lookup(label_str), depth=NUM_CLASSES, dtype=tf.float32)\n",
    "    return img, y\n",
    "\n",
    "def read_csv_dataset(csv_path, training: bool, batch_size=32, shuffle_buffer=2048):\n",
    "    ds = tf.data.TextLineDataset(str(csv_path)).skip(1)\n",
    "\n",
    "    def _split(line):\n",
    "        parts = tf.strings.split(line, sep=\",\")\n",
    "        return parts[0], parts[1]\n",
    "\n",
    "    ds = ds.map(_split, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(shuffle_buffer, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p,l: parse_row(p, l, training), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_ds = read_csv_dataset(TRAIN_CSV, training=True, batch_size=BATCH_SIZE)\n",
    "val_ds = read_csv_dataset(VAL_CSV, training=False, batch_size=BATCH_SIZE)\n",
    "test_ds = read_csv_dataset(TEST_CSV, training=False, batch_size=BATCH_SIZE) if TEST_CSV.exists() else None\n",
    "\n",
    "# Steps per epoch (full epochs)\n",
    "def count_rows(csv_path):\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        return sum(1 for _ in csv.DictReader(f))\n",
    "\n",
    "steps_per_epoch = math.ceil(count_rows(TRAIN_CSV) / BATCH_SIZE)\n",
    "val_steps = math.ceil(count_rows(VAL_CSV) / BATCH_SIZE)\n",
    "\n",
    "# (Optional) class weights, but cap to avoid instability\n",
    "def class_counts(csv_path):\n",
    "    cnt = Counter()\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            cnt[row[\"label\"]] += 1\n",
    "    return cnt\n",
    "\n",
    "cnts = class_counts(TRAIN_CSV)\n",
    "total = sum(cnts.values())\n",
    "raw_w = {LABEL2ID[c]: total / (NUM_CLASSES * max(1, cnts.get(c, 0))) for c in CLASSES}\n",
    "class_weights = {k: min(v, 2.0) for k, v in raw_w.items()}\n",
    "print(\"Class counts:\", cnts)\n",
    "print(\"Class weights (capped):\", class_weights)\n",
    "\n",
    "try:\n",
    "  from keras import mixed_percision\n",
    "  mixed_percision.set_global_policy(\"mixed_float16\")\n",
    "  FINAL_DTYPE = \"float32\"\n",
    "except Exception:\n",
    "  FINAL_DTYPE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y7ccBt8HnyOr",
   "metadata": {
    "id": "y7ccBt8HnyOr"
   },
   "source": [
    "## 3) Fire Block (Squeeze–Expand module)\n",
    "\n",
    "The *Fire module*:\n",
    "1. **Squeeze** — 1×1 conv reduces channel dimension (bottleneck).  \n",
    "2. **Expand** — parallel 1×1 and 3×3 convs re-expand to higher dimension.  \n",
    "3. **Concatenate** — merge both outputs → rich mixed receptive fields.  \n",
    "4. **Residual** (optional) — adds input back after channel alignment.  \n",
    "\n",
    "> Dropout and LayerNorm stabilize training and improve regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bf1d9-8f24-48da-aa61-6ffe9cdab615",
   "metadata": {},
   "source": [
    "## Architecture Overview & Tunable Parameters\n",
    "\n",
    "**Stem:** 3×3 Conv (stride 2) + LN + ReLU  \n",
    "**Core:** Two Fire stacks (each: non-residual + residual) before and after a downsampling conv  \n",
    "**Head:** GAP → Dense (128–192) → Dropout(0.35) → Softmax  \n",
    "\n",
    "**Hyperparameter search space**\n",
    "| Parameter | Type | Range / Options |\n",
    "|------------|------|-----------------|\n",
    "| `stem_filters` | Choice | [32, 48] |\n",
    "| `squeeze_filters` | Choice | [8, 16, 20] |\n",
    "| `expand_filters` | Choice | [32, 64, 80] |\n",
    "| `weight_decay` | Float(log) | 1e-5 – 5e-4 |\n",
    "| `drop_rate` | Float | 0.05 – 0.10 |\n",
    "| `dense_unit` | Choice | [128, 160, 192] |\n",
    "| `label_smoothing` | Choice | [0.05, 0.10] |\n",
    "| `lr` | Choice | [2e-3, 1e-3, 5e-4] |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WEo6C5t3nxXH",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760718817778,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "WEo6C5t3nxXH"
   },
   "outputs": [],
   "source": [
    "def Norm(): return layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "def fire_block(x, squeeze_filters, expand_filters, wd, drop=0.0, residual=False):\n",
    "    inp = x\n",
    "\n",
    "    # Squeeze\n",
    "    s = layers.Conv2D(filters=squeeze_filters, kernel_size=1, padding=\"same\", use_bias=False,\n",
    "                     kernel_regularizer=regularizers.l2(wd))(x)\n",
    "    s = Norm()(s)\n",
    "    s = layers.Activation(\"relu\")(s)\n",
    "\n",
    "    # Expand\n",
    "    e1 = layers.Conv2D(filters=expand_filters//2, kernel_size=1, padding=\"same\", use_bias=False,\n",
    "                      kernel_regularizer=regularizers.l2(wd))(s)\n",
    "    e1 = Norm()(e1)\n",
    "    e1 = layers.Activation(\"relu\")(e1)\n",
    "\n",
    "    e3 = layers.Conv2D(filters=expand_filters//2, kernel_size=3, padding=\"same\", use_bias=False,\n",
    "                      kernel_regularizer=regularizers.l2(wd))(s)\n",
    "    e3 = Norm()(e3)\n",
    "    e3 = layers.Activation(\"relu\")(e3)\n",
    "\n",
    "    x = layers.Concatenate()([e1, e3])\n",
    "\n",
    "    if residual:\n",
    "        # Match channel if needed\n",
    "        if inp.shape[-1] != x.shape[-1]:\n",
    "            inp = layers.Conv2D(filters=x.shape[-1], kernel_size=1, padding=\"same\", use_bias=False,\n",
    "                               kernel_regularizer=regularizers.l2(wd))(inp)\n",
    "            inp = Norm()(inp)\n",
    "        x = layers.Add()([x, inp])\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    if drop > 0:\n",
    "        x = layers.Dropout(drop)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_model_d(hp, input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    stem          = hp.Choice(\"stem_filters\", [32, 48])\n",
    "    wd            = hp.Float(\"weight_decay\", 1e-5, 5e-4, sampling=\"log\")\n",
    "    sq_filter     = hp.Choice(\"squeeze_filters\", [8, 16, 20])\n",
    "    expand_filter = hp.Choice(\"expand_filters\", [32, 64, 80])\n",
    "    drop          = hp.Float(\"drop_rate\", 0.05, 0.1, step=0.05)\n",
    "    head_units    = hp.Choice(\"dense_unit\", [128, 160, 192])\n",
    "    label_smooth  = hp.Choice(\"label_smoothing\", [0.05, 0.10])\n",
    "    lr            = hp.Choice(\"lr\", [2e-3, 1e-3, 5e-4])\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv2D(filters=stem, kernel_size=3, strides=2, padding=\"same\",\n",
    "                     kernel_regularizer=regularizers.l2(wd))(inputs)\n",
    "    x = Norm()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # Fire stack 1 (no downsample yet)\n",
    "    x = fire_block(x, squeeze_filters=sq_filter, expand_filters=expand_filter, wd=wd, drop=drop, residual=False)\n",
    "    x = fire_block(x, squeeze_filters=sq_filter, expand_filters=expand_filter, wd=wd, drop=drop, residual=True)\n",
    "\n",
    "    # Downsample\n",
    "    x = layers.Conv2D(filters=stem*3, kernel_size=3, strides=2, padding=\"same\",\n",
    "                     kernel_regularizer=regularizers.l2(wd))(x)\n",
    "    x = Norm()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # Fire stack 3\n",
    "    x = fire_block(x, squeeze_filters=sq_filter*2, expand_filters=expand_filter*2, wd=wd, drop=drop+0.05, residual=False)\n",
    "    x = fire_block(x, squeeze_filters=sq_filter*2, expand_filters=expand_filter*2, wd=wd, drop=drop+0.05, residual=True)\n",
    "\n",
    "    # Head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(head_units, activation=\"relu\", kernel_regularizer=regularizers.l2(wd))(x)\n",
    "    x = layers.Dropout(0.35)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"ModelD_SqueezeFire_GN\")\n",
    "\n",
    "    loss = keras.losses.CategoricalCrossentropy(label_smoothing=label_smooth)\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    metrics = [keras.metrics.CategoricalAccuracy(name=\"accuracy\")]\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h2m2zRgIvP3_",
   "metadata": {
    "id": "h2m2zRgIvP3_"
   },
   "source": [
    "## 4) Bayesian Hyperparameter Optimization\n",
    "\n",
    "We use **KerasTuner (BayesianOptimization)** to maximize validation accuracy.  \n",
    "- 12 trials, early stopping on `val_accuracy`  \n",
    "- Each trial runs up to 36 epochs  \n",
    "- `.repeat()` dataset for consistent step scheduling  \n",
    "- Val monitoring ensures stability over multiple seeds.  \n",
    "\n",
    "> Label smoothing prevents overconfidence, improving calibration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uxaW1SibvVJD",
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1760718840604,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "uxaW1SibvVJD"
   },
   "outputs": [],
   "source": [
    "tuner_d = kt.BayesianOptimization(\n",
    "    hypermodel=lambda hp: build_model_d(hp, input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES),\n",
    "    objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=12,                 \n",
    "    executions_per_trial=1,\n",
    "    directory=Path(\"rps_outputs/hpo\"),\n",
    "    project_name=\"model_d_squeezefire\",\n",
    "    overwrite=True,\n",
    "    max_consecutive_failed_trials=20,\n",
    ")\n",
    "\n",
    "search_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True), \n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "SEARCH_STEPS = steps_per_epoch      \n",
    "SEARCH_VAL_STEPS = val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Z31Q3122HV7",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Z31Q3122HV7"
   },
   "outputs": [],
   "source": [
    "tuner_d.search(\n",
    "    train_ds.repeat(),\n",
    "    validation_data=val_ds.repeat(),\n",
    "    steps_per_epoch=SEARCH_STEPS,\n",
    "    validation_steps=SEARCH_VAL_STEPS,\n",
    "    epochs=36,  \n",
    "    callbacks=search_callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "best_hps_d = tuner_d.get_best_hyperparameters(1)[0]\n",
    "print(\"Best HPs (Model D):\", best_hps_d.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e211c-17d2-47c6-9f99-78b248cbb802",
   "metadata": {},
   "source": [
    "## 5) Final Training\n",
    "\n",
    "- Rebuild model with best hyperparameters  \n",
    "- Train up to 40 epochs with patience = 8 on `val_loss`  \n",
    "- Use class weighting (capped ≤ 2.0) for stability  \n",
    "- Callbacks: Checkpoint, EarlyStopping, ReduceLROnPlateau  \n",
    "- Save best model: `model_d_hpo_final.keras`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fx7943dE3rxJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161336,
     "status": "ok",
     "timestamp": 1760705810282,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "Fx7943dE3rxJ",
    "outputId": "4e7904f0-3cfe-4deb-b125-945504d1ab78",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_D = tuner_d.hypermodel.build(best_hps_d)\n",
    "\n",
    "full_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(str(RPS / \"model_d_best.keras\"),\n",
    "                                    monitor=\"val_accuracy\", mode=\"max\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "history_d = MODEL_D.fit(\n",
    "    train_ds.repeat(),\n",
    "    validation_data=val_ds.repeat(),\n",
    "    steps_per_epoch=SEARCH_STEPS,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=40,\n",
    "    callbacks=full_callbacks,\n",
    "    class_weight=class_weights,\n",
    ")\n",
    "\n",
    "print(dict(zip(MODEL_D.metrics_names, MODEL_D.evaluate(test_ds, verbose=0))))\n",
    "MODEL_D.save(\"rps_outputs/model_d_hpo_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dce17b-b388-4d3f-9d96-2a1961dc7707",
   "metadata": {},
   "source": [
    "## 6) Evaluation & Curves\n",
    "\n",
    "- Evaluate on test set (loss + accuracy)  \n",
    "- Generate confusion matrix & classification report  \n",
    "- Plot training and validation accuracy/loss curves  \n",
    "- Compare to Model C: higher capacity, but slower and slightly more overfitting-prone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab7eac-ab8e-4c8a-a28d-47af6fc3b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "for x,y in (test_ds or val_ds):\n",
    "    p = MODEL_D.predict(x, verbose=0)\n",
    "    y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(p, axis=1))\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dbf43-966b-4fed-bce1-68b6d658e359",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1760705871095,
     "user": {
      "displayName": "Arman Rashidizadeh",
      "userId": "12824478322259522985"
     },
     "user_tz": -120
    },
    "id": "ac5dbf43-966b-4fed-bce1-68b6d658e359",
    "outputId": "d4bc317e-230a-4e43-b845-df8efec03b51"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_d.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history_d.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(\"Model D Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_d.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history_d.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"Model D Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384568-ba48-4422-9b57-f35c04530922",
   "metadata": {},
   "source": [
    "- The **Fire module** efficiently balances computation and representation power.  \n",
    "- Adding residuals improves convergence speed and stability.  \n",
    "- Validation accuracy plateaued early (~25 epochs).  \n",
    "- Overfitting tendency increases with larger `expand_filters`; optimum ≈ 64.  \n",
    "- Highest test accuracy: ≈ 0.95 – 0.96.  \n",
    "- Among all, Model B remains the most efficient trade-off between accuracy and speed,  \n",
    "  while Model D demonstrates scalability potential for larger datasets.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
